{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![avatar](./rnn.png)\n",
    "### 如图，$x^{(t)}$，$h^{(t)}$，$o^{(t)}$，$L^{(t)}$，$y^{(t)}$分别表示t时刻样本输入、隐藏状态、模型输出、损失函数、真实输出，U,W,V为对应的模型参数矩阵。\n",
    "### 根据前向传播算法，已知：\n",
    "\\begin{eqnarray}\n",
    "&&h^{(t)} = \\sigma(z^{(t)}) = \\sigma(Ux^{(t)} + Wh^{(t-1)} +b )\\\\\n",
    "\\\\\n",
    "&&o^{(t)} = Vh^{(t)} +c\\\\\n",
    "\\\\\n",
    "&&\\hat{y}^{(t)} = \\sigma(o^{(t)})\\\\\n",
    "\\end{eqnarray}\n",
    "这里隐藏状态的激活函数定为tanh，输出的激活函数定为softmax。\n",
    "### U,W,V,b,c 在序列的各个位置是共享的。\n",
    "### 确定损失函数L为：\n",
    "\\begin{eqnarray}\n",
    "L = \\sum\\limits_{t=1}^{T}L^{(t)}\n",
    "\\end{eqnarray}\n",
    "### 首先求解V，c的梯度，得：\n",
    " \\begin{eqnarray}\n",
    "&&\\frac{\\partial L}{\\partial c} = \\sum\\limits_{t=1}^{T}\\frac{\\partial L^{(t)}}{\\partial c} = \\sum\\limits_{t=1}^{T}\\frac{\\partial L^{(t)}}{\\partial o^{(t)}} \\frac{\\partial o^{(t)}}{\\partial c} = \\sum\\limits_{t=1}^{T}\\hat{y}^{(t)} - y^{(t)}\\\\\n",
    "\\\\\n",
    "&&\\frac{\\partial L}{\\partial V} =\\sum\\limits_{t=1}^{T}\\frac{\\partial L^{(t)}}{\\partial V} = \\sum\\limits_{t=1}^{T}\\frac{\\partial L^{(t)}}{\\partial o^{(t)}} \\frac{\\partial o^{(t)}}{\\partial V} = \\sum\\limits_{t=1}^{T}(\\hat{y}^{(t)} - y^{(t)}) (h^{(t)})^T\n",
    "\\end{eqnarray}  \n",
    "\n",
    "### 定义t时刻隐藏状态的梯度$\\delta^{(t)}$：\n",
    "\\begin{eqnarray}\n",
    "\\delta^{(t)} = \\frac{\\partial L}{\\partial h^{(t)}}\n",
    "\\end{eqnarray}\n",
    "### 对于T时刻，由于后面没有其他序列了，可直接求得：\n",
    "\\begin{eqnarray}\n",
    "\\delta^{(T)} =\\frac{\\partial L}{\\partial o^{(T)}} \\frac{\\partial o^{(T)}}{\\partial h^{(T)}} = V^T(\\hat{y}^{T)} - y^{(T)})\n",
    "\\end{eqnarray}\n",
    "### 像DNN一样，可由$\\delta^{(t+1)}$推导出$\\delta^{(t)}$：\n",
    "\\begin{eqnarray}\n",
    "\\delta^{(t)} =\\frac{\\partial L}{\\partial o^{(t)}} \\frac{\\partial o^{(t)}}{\\partial h^{(t)}} + \\frac{\\partial L}{\\partial h^{(t+1)}}\\frac{\\partial h^{(t+1)}}{\\partial h^{(t)}} = V^T(\\hat{y}^{(t)} - y^{(t)}) + W^T\\delta^{(t+1)}diag(1-(h^{(t+1)})^2)\n",
    "\\end{eqnarray}\n",
    "### 有了$\\delta^{(t)}$，接着可求出W,U,b 的梯度：\n",
    "\\begin{eqnarray}\n",
    "&&\\frac{\\partial L}{\\partial W} =  \\sum\\limits_{t=1}^{T}\\frac{\\partial L}{\\partial h^{(t)}} \\frac{\\partial h^{(t)}}{\\partial W} = \\sum\\limits_{t=1}^{T}diag(1-(h^{(t)})^2)\\delta^{(t)}(h^{(t-1)})^T\\\\\n",
    "\\\\\n",
    "&&\\frac{\\partial L}{\\partial b}= \\sum\\limits_{t=1}^{T}\\frac{\\partial L}{\\partial h^{(t)}} \\frac{\\partial h^{(t)}}{\\partial b} = \\sum\\limits_{t=1}^{T}diag(1-(h^{(t)})^2)\\delta^{(t)}\\\\\n",
    "\\\\\n",
    "&&\\frac{\\partial L}{\\partial U} = \\sum\\limits_{t=1}^{T}\\frac{\\partial L}{\\partial h^{(t)}} \\frac{\\partial h^{(t)}}{\\partial U} = \\sum\\limits_{t=1}^{T}diag(1-(h^{(t)})^2)\\delta^{(t)}(x^{(t)})^T\n",
    "\\end{eqnarray}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
